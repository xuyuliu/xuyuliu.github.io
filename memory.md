---
permalink: /memory.html
---

# 内存虚拟化

## 内存虚拟化原因和要求
### 好处
* 便于编程，不必考虑实际地址
* 时间空间效率更高
* 保证进程之间相互隔离，互不干扰
### 系统需求
* 透明性：对进程而言是透明的，无竞争
* 保护：
  * 操作系统代码不能被访问
  * 进程之间不能相互访问
* 效率：内存资源不被浪费，不引入额外负担
* 共享：让进程之间可以共享部分内存空间
### 进程逻辑地址需求
* 地址空间：对内存的抽象。把进程相关的数映射到地址空间，各进程有独立的逻辑空间
  * heap：顶部，小->大
  * stack：底部：大->小
  * 保存：基地址、偏移量
* 地址转换
  * 将虚拟地址转换为物理地址
  * 转换时间：进程创建、结束、切换


## 空闲空间管理
### 碎片
* 外部碎片：已经分配出去的内存被浪费
  * 解决方案：紧缩，将空间空间合并为一整块
* 内部碎片：回收后的内存，未分配但是不能被使用
### 空间分配
* 从内存角度
  * 按需分配，根据进程要求
  * 预先分配，提前切成大小固定块
* 具体分配方式
  * 内存提前切割好，将整个进程放入一个块中
    * 块大小可以相等或不相等
    * 操作简单
    * 不实用，会产生内部碎片
  * 连续内存，动态切割
    * 会产生外部碎片
  * 进程静态/动态分配
    * 静态：进程在运行之前就确定空间大小，运行时不改变
    * 动态：运行中动态增长，如malloc
  * 内存固定切割/可变切割
  * 将进程分割成大小相等的页，放入内存不同区域(分页)
    * 分页方式：将进程切割成大小相等的页，内存也分割成大小相同的页框
    * 优势：进程和内存大小相等，空间管理和分配较简单
  * 将进程切成大小不等的段(分段)
### 空间追踪与合并
* 链表表示
  * 在分割时使用链表表示，记录开始的地址和大小
  * 分配时有额外空间标记分配的空间和大小：便于回收
  * 分离列表
    * 将大小范围不同的放入不同列表中，搜索复杂度更低
    * 回收时直接放入对应列表中即可
    * 优点：速度更快，不必全部遍历
    * 极端情况：每个大小均有一个列表
  * 厚块分配(Slab Allocator)：预先申请较大内存，再进行分割，主要用于使用频繁、大小较小的内存需求
  * 伙伴系统(Buddy Allocation)：按照2^N的方式进行分割，便于合并
* 合并策略
  * 立即合并：每次需要遍历，复杂度较高
  * 推迟合并：空间不够时再进行分配
* 回收策略
  * 插入链表开头
  * 按照地址排序：便于合并
  * 按照大小排序：便于分配
* 分配策略
  * 最佳匹配(best fit)：选择最接近的进行匹配
    * 时间代价较高
  * 最差匹配(worst fit)：寻找最大项进行分配
    * 时间代价高且会产生较多碎片
  * 首次匹配(first fit)：第一个满足要求的块
    * 重复使用同一个位置
    * 速度较快
  * 下次匹配(next fit)：从上一次分配的位置开始搜索，首个满足的块
    * 避免遍历和对开头区域的重复使用




## 段式管理
### 分块方式
* 粗粒度：按照进程本身的code、heap、stack形式划分
* 细粒度：更加灵活
### 段地址转换
* 逻辑地址：段号，偏移
* 段表实现映射关系：段基地址和段界限
对逻辑地址和物理地址进行编号，物理地址=段号+虚拟地址
### 实现共享
* 映射到同一物理区域
* 限制读写权限


## 页式管理
### 核心思想
将进程逻辑地址空间分成大小相等的页(page)，将内存空间也分成同样大小的页帧(frame)
### 地址转换
* 逻辑地址=页号+页内偏移量，将页号替换成物理地址帧号
* 页表：记录虚拟页号与物理帧号的对应关系，由进程维护
* 问题：较慢，需要访问两次内存，查页表和内存
### 页表过大
* 将页大小变大
  * 缺点：会产生内部碎片问题
* 将段式管理与页式管理结合
  * 将进程划分为段，每个段中有多个页
  * 段优势：支持稀疏的地址空间
  * 页优势：没有外部碎片
* 多级页表
  * 将页表切成大小相同的页
  * 设置目录表，可以有多级
  * 无效页表不用表示
  * 优势：节省空间，支持增长
  * 缺点：牺牲时间
* 反向页表/倒排页表
  * 整个系统保留一个页表，记录使用的物理页帧
  * 使用hash进行记录

### TLB
* 页式管理不足：页表较大
* 解决方式：使用cache缓存
  * 成本高，大小较小->只能存放部分内容
* 局部性要求
  * 时间局部性：短期内访问次数较多
  * 空间局部性：内存地址较为靠近
* 提升命中率
  * 增大页面大小
  * TLB替换算法
* 不命中处理方式
  * CISC：由硬件实现，将物理地址放入TLB中
  * RISC：由软件处理，提权到内核态，使用陷入处理
* 进程切换
  * 各进程不同页表都存储再TLB中，若无PID，会引起歧义
  * 切换时，全部更新TLB中的内容
  * 在TLB中增加ASID，与PID类似，更短
  * TLB也可映射到同一空间实现共享


### 交换
* 实现快速和大容量的需求，将不用的放在外存的交换空间之中
  * 每个进程在运行中并非所有页面都可以被用到
  * 内存空间装满：将暂时不用的部分交换进去
* 页表中需要加入present bit，指示是否在内存中
* 缺页：在硬盘中查找，进行替换
  * 替换时机：
    * 被动
    * 主动，预取替换
### 替换算法
* 评价指标 AMAT，平均内存访问时间
* OPT
  * 在未来一段时间不会被用到的替换出去
  * 只能事后判断，是理想化的方法
  * 未命中次数最低
* FIFO
  * 先入先出，维护一个队列，实现方便
  * 无法确定页的重要性，即无法确定最近是否还会使用
  * Belady异常：增加缓存大小反而命中率降低
* RAND
  * 随机访问，一些情况下也可取得较好效果
* LRU
  * 将最久未访问的替换出去
  * 可提高命中率
  * 相反的思路MRU，忽视局部性特点，效果不好
* LFU
  * 将访问频率最低的替换出去
  * 基于局部性原则
  * 但是维护开销较大
  * 也有相反的思路MFU，忽视局部性特点，效果不好
* CLOCK
  * 近似LRU的方式
  * 将所有也放在循环列表中
  * 通过使用位的值进行判断是否最近被使用过
    * 找到第一个为0的位置进行替换
    * 在寻找过程中将1置为0
    * 使用位可以使用多位存储
* 脏页
  * 记录页面是否被修改
  * 倾向踢出干净页
* 预取
  * 推测接下来使用页面的可能
